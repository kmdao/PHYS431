{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johnson and Shot Noise Analysis (2024)\n",
    "\n",
    "#### This template assumes use of the new shot noise source\n",
    "\n",
    "Use this template to carry out the analysis tasks for the Noise experiment.  For reference, here are links to recommended Python resources: the [Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/) and the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) both by Jake VanderPlas.\n",
    "## First, import some packages\n",
    "\n",
    "This is a good idea at the beginning of your notebook to include the packages that you will need.  We will use those shown below here.  A brief description:\n",
    "* `numpy` is the foundational package for Python numerical work. It extends and speeds up array operations beyond standard Python, and it includes almost all math functions that you would need for example `sqrt()` (square root) or `cos()` (cosine).  These would be written in code as `np.sqrt()` or `np.cos()`.\n",
    "* `scipy` is a huge collection of scientific data analysis functions, routines, physicical constants, etc.  This is the second most used package for scientific work. Here we will use the physical constants library, `scipy.constants`.  Documentation is at [SciPy.org](https://docs.scipy.org/doc/scipy/reference/) with the constants subpackage at https://docs.scipy.org/doc/scipy/reference/constants.html.\n",
    "* `uncertainties` is a very useful small package that simplifies uncertainty propagation and printing out of quantities with uncertainty. Documentation is at https://pythonhosted.org/uncertainties/\n",
    "* `matplotlib` is *the* standard plotting package for scientific Python.  We will use a subset called `pyplot` which is modeled after the plotting functions used in MATLAB. The last line below, `%matplotlib inline`, simply forces the plots to appear within the notebook.\n",
    "* `pandas` is a large data science package.  It's main feature is a set of methods to create and manipulate a \"DataFrame,\" which is an enlargement of the idea of an array.  I plays well with NumPy and other packages.  We will use it mainly as a way to read files into data sets in an easy way.\n",
    "\n",
    "We will also use the [LMFit](https://lmfit.github.io/lmfit-py/) package to make line fits.  This will be explained later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell with Shift-Enter, and wait until the \n",
    "# asterisk changes to a number, i.e., [*] becomes [1]\n",
    "import numpy as np\n",
    "import scipy.constants as const\n",
    "import uncertainties as unc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Johnson Noise Analysis\n",
    "\n",
    "## Exercise 1 -  Data reduction\n",
    "### Read in the raw data\n",
    "\n",
    "**About Data Files:** This template assumes that the data files will have one of two types of structure: \n",
    "1. If you took 5 readings (or so) for each measurement and plan to average them here, the assumed structure is one where each spreadsheet column is named with the resistance (for Johnson Noise), e.g., \"9.99k\", or the emission current (for shot noise), e.g., \"0.1047mA\" and each row of the data is one trial with each cell containing the measured RMS voltage in the frequency band; \n",
    "2. If you opted instead to simply take one longer-average time measurement for each resistance (or emission current), then the assumed structure would be two columns, the first column headed with resistance (or emission current) and the second column headed with the measured RMS voltage in the frequency band.\n",
    "\n",
    "Below, these structures are treated by the designation \"1\" or \"2\".  Stucture type \"1\" requires a little more effort to reduce, but offers the option of calculating data point uncertainties. \n",
    "\n",
    "**Advice:** Use the **Pandas** function `read_csv()` to pull the file into a Pandas Dataframe, like this:\n",
    "\n",
    "    johnson_294 = pd.read_csv('Johnson_294K.csv')\n",
    "\n",
    "If the last line in the code cell is the name of the DataFrame (`johnson_294`), the notebook cell will print a nice table.\n",
    "\n",
    "You may obtain the arrays for each column by using the column label, e.g., `johnson_294['40.0k']` is the array of the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Johnson300k.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Lines below show how to read in a CSV data set and display it.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m johnson_294 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJohnson300k.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m johnson_294\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Johnson300k.csv'"
     ]
    }
   ],
   "source": [
    "## Lines below show how to read in a CSV data set and display it.\n",
    "\n",
    "johnson_294 = pd.read_csv('Johnson300k.csv', delimiter=',')\n",
    "johnson_294  # DataFrame name on the last line spits out a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massage the raw data\n",
    "\n",
    "#### For data structure type \"1.\"  If you have a type \"2\" data structure, skip to \"Plot the Reduced Data\" below.\n",
    "\n",
    "Create new arrays that have averages of the 5 readings at each value of the resistance and their standard deviation.  Then extract the resistance from the column label and make into a number.  Finally, build a new DataFrame that has these arrays. Below is an example.  The example shows a number of useful operations.  Study it carefully.\n",
    "\n",
    "We will use a loop to build the new arrays first, and then combine them into a DataFrame.\n",
    "\n",
    "You can extract the resistance from the column heading. Here is one way to do it, assuming `col_label` is the column label:\n",
    "\n",
    "    resistance = float(col_label.split('k')[0])\n",
    "    \n",
    "This splits the label at `k` and puts the number into the first (0) position as a string.  `float()` converts the number string to a flaoting point number.\n",
    "\n",
    "Then calculate the mean and standard deviation using the built-in methods for the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Study this example.\n",
    "\n",
    "# These lines create empty arrays that will be filled.\n",
    "Rs = np.zeros(0)\n",
    "Vs = np.zeros(0)\n",
    "Stds = np.zeros(0)\n",
    "\n",
    "# This is a standard Python loop.  Note the 'for <item> in <list>:' construction\n",
    "# The '.columns' is an array of column labels in the DataFrame\n",
    "for label in johnson_294.columns:\n",
    "    # obtain the numerical part of the column label\n",
    "    R = float(label.split('k')[0])\n",
    "    # calculate the mean (average) of the numbers in the column\n",
    "    mean = johnson_294[label].mean()\n",
    "    # calculate the standard deviation of the same numbers \n",
    "    std = johnson_294[label].std()\n",
    "    \n",
    "    # These lines add each calculated result to the associated array\n",
    "    Rs = np.append(Rs,R)\n",
    "    Vs = np.append(Vs,mean)\n",
    "    Stds = np.append(Stds,std)\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "J_294 = pd.DataFrame()\n",
    "\n",
    "# These lines add columns to the DataFrame\n",
    "J_294['R (ohms)'] = Rs*1000.0 # Convert resistance from kohms to ohms\n",
    "J_294['Vrms (V)'] = Vs\n",
    "J_294['DV (V)'] = Stds\n",
    "\n",
    "# Here is another way to do the same thing\n",
    "\n",
    "J_294_ver2 = pd.DataFrame({\n",
    "    'R (ohms)': Rs*1e3,\n",
    "    'Vrms (V)': Vs,\n",
    "    'DV (V)': Stds\n",
    "})\n",
    "\n",
    "# Finally display the results.  Name of DataFrame on last line spits a table\n",
    "# J_294\n",
    "J_294_ver2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat for the other temperature \n",
    "\n",
    "Now you try it for the other temperature data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data set and display it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the averages of each column.\n",
    "## extract the values of the resistance.  \n",
    "## Build a (new) dataframe and display it to see if it looks right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the reduced data\n",
    "\n",
    "Plot the data set of $V_{rms}$ vs $R$ to see what it looks like.\n",
    "\n",
    "Below, I'll show how. Study the commands, change them, and see what happens.  Hint: study the sections in the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) on Matplotlib. \n",
    "\n",
    "After you make the plot, always look to make sure your data set does not have any weird points. This is a good way to catch bad data and/or mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plot defaults  This cell only needs to be executed once.\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 10.0,8.0  # Roughly 11 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 12.0 # Use 12 point font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the data sets on one graph\n",
    "## Header commands provided\n",
    "\n",
    "plt.grid() # Turn on the grid\n",
    "plt.title('Johnson Noise Data') # make a plot title\n",
    "plt.ylabel(r'$V_J$ (Vrms)') # Make an axis label.  Note the $$ to typeset math\n",
    "plt.xlabel(r'Resistance $R$ ($\\Omega$)') #Another axis label\n",
    "\n",
    "# Below shows how to make a plot with error bars.  The errors are multiplied by \n",
    "# 10 so that the bars are visible. \n",
    "\n",
    "# If you have no error bars, simply omit the item 'yerr=J_294['DV (V)']*10'\n",
    "\n",
    "plt.errorbar(J_294['R (ohms)'],J_294['Vrms (V)'],\n",
    "             yerr=J_294['DV (V)']*10,\n",
    "             fmt='o',label='T = 295K')\n",
    "plt.legend(); # Make a legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include the other data\n",
    "\n",
    "Repeat the lines in the cell above and include another data set so that both the 395K and 77K data are on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You code this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "### Part a.  Modify the data\n",
    "\n",
    "Modify the data arrays to obtain the mean square voltages for each temperature, and also the difference in the (squared) data for the two temperatures, which will help remove the effects of noise in the electronics.  **Remember:** You have NumPy/Pandas arrays, so you can do each task with a single line of code.\n",
    "\n",
    "Then plot the results, all on one plot so you can compare them visually.\n",
    "\n",
    "#### For data sets that have uncertainties associated with them. \n",
    "\n",
    "If you have uncertainties on each data point that you want to carry forward in the analysis, when you square the value, the uncertainty is NOT also squared. Instead it is multiplied by 2 times the |value|.  That is, if $\\sigma_x$ is the uncertainty in $x$, the uncertainty in $x^2$ is $\\sigma_{x^2} = 2|x|\\sigma_x$. \n",
    "\n",
    "Another way to work out the uncertainties is to first build arrays of uncertainty objects from the data and uncertainty arrays. For example, if the data are in an array called `X` and the uncertainty (i.e., error bars) are in an array called `sigma_X`, you can build an uncertainty array as follows:\n",
    "\n",
    "    # Import uNumPy functions.  You could do this in the first cell\n",
    "    import uncertainties.unumpy as unp\n",
    "    \n",
    "    # Build an uncertainty array\n",
    "    uX = unp.uarray(X, sigma_X)\n",
    "    \n",
    "    # Square the array, and also propagate uncertainty\n",
    "    uX_sqrd = uX*uX\n",
    "    \n",
    "    # Access the parts of the uncertainty array.  This is necessary for curve fitting\n",
    "    uX_sqrd_values = unp.nominal_values(uX_sqrd)\n",
    "    uX_sqrd_sigmas = unp.std_devs(uX_sqrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify the arrays as specified above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the results\n",
    "## Header commands provided to format plot\n",
    "\n",
    "plt.grid()\n",
    "plt.title('Johnson Noise Data, in Quadrature')\n",
    "plt.ylabel(r'$V^2_J$ (Vrms$^2$)')\n",
    "plt.xlabel(r'Resistance $R$ ($\\Omega$)')\n",
    "## Add your code here\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b. Fit the modified data\n",
    "\n",
    "To fit the data set to a line, make use of the **LMFit** package. It is a useful add-on to the SciPy fitting functions.  This package simplifies fitting data to a variety of standard functions.  See the [Lmfit Documentation](https://lmfit.github.io/lmfit-py/index.html) for a full discussion.  The package is quite powerful, but for basic fitting with common functions, it is very easy to use.  \n",
    "\n",
    "#### Example: Fitting a line\n",
    "\n",
    "The example below shows how to use the package to fit data to a line, obtain the fit parameters along with uncertainties, and then plot the data and fit. Execute the cells and study how it works.\n",
    "(Note: the data come from a calibration problem in physics 331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only creates arrays of x and y data to feed to the fit example in the next cell.\n",
    "# Calibration Data from a physics 331 experiment.\n",
    "# First column is wavelength (nm), second is carriage position (cm)\n",
    "#\n",
    "Cal_data = np.array([\n",
    "    [643.85, 41.43],\n",
    "    [579.07, 37.24],\n",
    "    [576.96, 37.11],\n",
    "    [546.08, 35.10],\n",
    "    [508.58, 32.68],\n",
    "    [479.99, 30.83],\n",
    "    [467.81, 30.04],\n",
    "    [435.83, 27.96],\n",
    "    [404.66, 25.98]])\n",
    "\n",
    "# Array slicing separates x (position) and y (wavelength)\n",
    "# Goal of calibration is to be able to feed in a position and obtain a wavelength\n",
    "wavelength = Cal_data[:,0]\n",
    "position = Cal_data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell executes the fitting calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a linear fitting model from lmfit  \n",
    "# ONLY IMPORT ONCE IN A NOTEBOOK\n",
    "from lmfit.models import LinearModel\n",
    "\n",
    "# create an instance of the model\n",
    "# You only need to do this once in a notebook\n",
    "line = LinearModel()\n",
    "\n",
    "# One must have a guess of the parameters. The guess() method works with most of the standard\n",
    "# lmfit models\n",
    "\n",
    "# The return value is a Parameters structure.  See the documentation.\n",
    "param_guess = line.guess(wavelength, x=position)\n",
    "\n",
    "# The line below executes the fitting process.  The results are returned to \"line_fit\"\n",
    "line_fit = line.fit(wavelength, param_guess, x=position)\n",
    "\n",
    "# This prints the results in an easy to read form\n",
    "print(line_fit.fit_report())\n",
    "\n",
    "#Then you can plot the results quickly just to see how it looks using the plot() method\n",
    "line_fit.plot()\n",
    "# Optional: Change axis labels from default 'X' vs. 'Y'.\n",
    "plt.xlabel('Carriage position (cm)')\n",
    "plt.ylabel('Emission wavelength (nm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit each to a line and obtain the slope with uncertainty.  Plot the data with the fit lines.\n",
    "\n",
    "First, I'll make functions to clean up the coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defines a function to do the work.  Study it.  If you don't understand how this works,\n",
    "## find out by asking questions and or studying the functions in the code.\n",
    "\n",
    "def line_fit_and_plot(xdata, ydata, yerr=None, model=LinearModel(), xlabel='X', ylabel='Y'):\n",
    "    '''\n",
    "    Fit a line or curve, and plot/show the fit results.\n",
    "    The function returns a parameters object with the fit parameters\n",
    "    '''\n",
    "    param_guess = model.guess(ydata, x=xdata)\n",
    "    if (yerr is None):\n",
    "        model_fit = model.fit(ydata, param_guess, x=xdata)\n",
    "    else:\n",
    "        model_fit = model.fit(ydata, param_guess, x=xdata, weights=1/yerr)\n",
    "    print(model_fit.fit_report(show_correl=False))\n",
    "    model_fit.plot()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel);\n",
    "    return model_fit.params\n",
    "\n",
    "## This function use the Uncertainties function to make an uncertainty object\n",
    "\n",
    "def get_uslope(params):\n",
    "    return unc.ufloat(params['slope'].value, params['slope'].stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the functions above to run the fit for the modified 295K data\n",
    "## and save the fit parameters.  Then pull out the slope\n",
    "## Here is how you would use the above functions with the example data:\n",
    "\n",
    "# Run the fit\n",
    "example_fit_params = line_fit_and_plot(position,wavelength,\n",
    "                                       xlabel='Carriage position (cm)',ylabel='Emission wavelength (nm)')\n",
    "\n",
    "# Obtain the slope and its uncertainty into an uncertainty object\n",
    "slope_with_uncertainty = get_uslope(example_fit_params)\n",
    "print('\\nSlope = {:.2uP}'.format(slope_with_uncertainty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a Boltzmann constant\n",
    "\n",
    "From the results, calculate the implied Boltzmann constant (with uncertainty).\n",
    "\n",
    "Revised gain of low-noise amplifier $G=10122\\pm35$ (as of July 2021, DBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create uncertainties objects for the other quantities.  The first two are examples\n",
    "T_295 = unc.ufloat(295.0,1.0) # K\n",
    "G = unc.ufloat(10122,35) # unitless\n",
    "k_B = const.Boltzmann # J/K Accepted value of Boltsmann constant from SciPy constants library.\n",
    "# You do the rest\n",
    "\n",
    "\n",
    "## Calculate and print k_Boltzmann\n",
    "# Use the following print line:\n",
    "# print('Boltzmann constant from T = 295K data = {:.2uP} J/K'.format(k_295))\n",
    "# print('Accepted value = {:.4g} J/K'.format(k_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 77 K data\n",
    "Repeat the process for the 77K data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat for the 77K data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the difference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat for the \"difference\" data (295K-77K) subracted in quadrature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot everything on one graph\n",
    "\n",
    "Make a single plot that shows all three sets of data (as points) and the three fit lines (as lines).  Include a legend.\n",
    "\n",
    "The cell below shows how to create a fit line using an arbitrary set of x-values based on the range of x data.  It uses the example data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a \"fit line\" based on the obtained fit parameters\n",
    "\n",
    "xvalues = np.linspace(position.min(),position.max(),100) # create a set of 100 evenly-spaced points\n",
    "yvalues = line.eval(example_fit_params, x=xvalues) # The first argument to eval() needs to be the fit parameters object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, it is your turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make single a plot of all data and fit lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c.\n",
    "\n",
    "Summary of results for Boltsmann constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize the results in one table\n",
    "## Like so:\n",
    "## print('  T (K)  |  k_B (J/K)   ')\n",
    "## print('---------|--------------------')\n",
    "## print('   295   | {:.1uP}'.format(k_295))\n",
    "## print('    77   | {:.1uP}'.format(k_77))\n",
    "## print(' 295-77  | {:.1uP}'.format(k_218))\n",
    "## print('Accepted | {:10.4g}'.format(k_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Noise Figure\n",
    "\n",
    "Calculate the \"noise figure\" for the low-noise amp, as described in the instructions.\n",
    "\n",
    "The noise figure is defined:\n",
    "\n",
    "$$ NF = 20\\log_{10}\\frac{V_{rms}(R)}{G\\times\\sqrt{4k_BTRB}} \\; \\text{dB}$$\n",
    "\n",
    "Please limit the noise figure to 2 digits beyond the decimal point.  \n",
    "\n",
    "Note: It clearly does not work for $R=0$.  You will need to leave this out of the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Noise figure for the various values of R at \n",
    "## room temperature and display it as a table or a plot\n",
    "\n",
    "## Make a data frame to display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot Noise Analysis\n",
    "\n",
    "This is very similar to the Johnson noise analysis.\n",
    "\n",
    "### Read in the data\n",
    "\n",
    "For data structure type \"1\", column names like \"0.1202mA\" need to split at `m` to convert the current labels into currents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Read in the shot noise data and display it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain averages\n",
    "\n",
    "For Data structure type \"1\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the averages and extract the values of the emission current.  \n",
    "## Display the results to check.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $V^2_{rms}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## transform the data, like you did with Johnson noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then fit it and plot it\n",
    "\n",
    "**Note:** Shot nose data may not be \"pure\" in that you will see a notable deviation from the expected behavior.  The data may be affected by $1/f$ noise in the vacuum diode that gets worse with higher emission current.   This effect is reduced in the newer shot noise apparatus that uses a different vacuum diode.  If you see a notable curve in your measured voltage, you may try a couple of work-arounds to obtain the linear part of the noise-squared vs emission current:\n",
    "\n",
    "1. Select a portion of the data to fit, where the $1/f$ problem is less, near the low-emission current end of the data set.\n",
    "2. Make a ploynomial fit and look at the linear term.\n",
    "\n",
    "You should try a couple of options and compare your results with your partners.  You only need to do this if you see the $1/f$ effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First the fit. Try the whole data set first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then try the lower half of the data, before the 1/f takes over, if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Another way out of the $1/f$ problem is to fit a quadratic, and use the linear-term coefficient as the initial slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do this, you need a different fitting model\n",
    "#  Below will get you started, but you need to study the docs to understand the parameters.\n",
    "\n",
    "from lmfit.models import QuadraticModel\n",
    "quadratic = QuadraticModel()\n",
    "\n",
    "## You do the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now make a nice plot of all fits over the data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Electron Charge\n",
    "\n",
    "Use the fit results, propagate the uncertainty, and find a value for $e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate e with uncertainty and print it (with units) \n",
    "## Compare with the accepted value\n",
    "\n",
    "# You will need the correct sensing resistance in the shot noise box:\n",
    "# Older box:\n",
    "# R_load = unc.ufloat(4976,1) # Load resistance of shot noise box in ohms \n",
    "# Newer box:\n",
    "# R_load = unc.ufloat(10000.0,10)\n",
    "\n",
    "# Calculate the result, and propagate the uncertainty.\n",
    "\n",
    "# Use whatever you need below\n",
    "# print('\\nElectron charge from whole data set = {:.2uP} C'.format(e_1))\n",
    "# print('Electron charge from partial data set = {:.2uP} C'.format(e_2))\n",
    "# print('Electron charge from quadratic fit = {:.2uP} C'.format(e_3))\n",
    "# print('\\nAccepted value = {:.4g} C'.format(const.e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Exercise: $1/f$ noise\n",
    "\n",
    "Measurements of the power spectral density in units of $V/\\sqrt{\\text{Hz}}$ were made from the \"1/f noise source\", along with the same values from the amplifier alone.  The curve shows a 1/f spectrum where $V^2 \\propto 1/f^\\alpha$.  In this exercise, one determines the exponent $\\alpha$.\n",
    "\n",
    "The data are in a file called `one_over_f_noise_data.csv`.  The first line of the data file must be skipped.  (Look at it to see why.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the \"subtract by quadrature\" game to remove the mostly constant background.\n",
    "\n",
    "## Convienence: pull out the frequency array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a plot  Use log axes to see a line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit a line to the log_10 of the data vs log_10 of the frequency.\n",
    "## The slope will be -alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the exponent from the fit\n",
    "\n",
    "# print('1/f noise exponent = {:.1uP}'.format(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
